"""snowflake_cache

Revision ID: 88e0bdcc08be
Revises: 2d3f169dfb3a
Create Date: 2025-07-22 11:02:06.703794

"""

from collections.abc import Sequence

import sqlalchemy as sa
import sqlmodel
from alembic import op
from sqlalchemy.dialects import postgresql
from sqlalchemy.dialects.postgresql import ENUM

# revision identifiers, used by Alembic.
revision: str = "88e0bdcc08be"
down_revision: str | None = "2d3f169dfb3a"
branch_labels: str | Sequence[str] | None = None
depends_on: str | Sequence[str] | None = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    # Define the enums
    granularity_enum = ENUM("DAY", "WEEK", "MONTH", "QUARTER", "YEAR", name="granularity", create_type=False)
    sync_status_enum = ENUM("SUCCESS", "FAILED", "RUNNING", name="syncstatus", schema="query_store", create_type=False)
    sync_operation_enum = ENUM(
        "SEMANTIC_SYNC", "SNOWFLAKE_CACHE", name="syncoperation", schema="query_store", create_type=True
    )

    op.create_table(
        "tenant_sync_status",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("created_at", sa.DateTime(), server_default=sa.text("current_timestamp(0)"), nullable=False),
        sa.Column("updated_at", sa.DateTime(), server_default=sa.text("current_timestamp(0)"), nullable=False),
        sa.Column("tenant_id", sa.Integer(), nullable=False),
        sa.Column(
            "sync_operation",
            sync_operation_enum,
            nullable=True,
        ),
        sa.Column("grain", granularity_enum, nullable=False),
        sa.Column("last_sync_at", sa.DateTime(), nullable=False),
        sa.Column(
            "sync_status",
            sync_status_enum,
            nullable=True,
        ),
        sa.Column("metrics_processed", sa.Integer(), nullable=True),
        sa.Column("metrics_succeeded", sa.Integer(), nullable=True),
        sa.Column("metrics_failed", sa.Integer(), nullable=True),
        sa.Column("error", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column("run_info", postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column("history", postgresql.JSONB(astext_type=sa.Text()), server_default="[]", nullable=False),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint("tenant_id", "sync_operation", "grain", name="uq_tenant_sync_status"),
        schema="query_store",
    )
    op.create_index(
        "idx_tenant_sync_status_last_sync",
        "tenant_sync_status",
        ["last_sync_at"],
        unique=False,
        schema="query_store",
        postgresql_ops={"last_sync_at": "DESC"},
    )
    op.create_index(
        "idx_tenant_sync_status_status", "tenant_sync_status", ["sync_status"], unique=False, schema="query_store"
    )
    op.create_index(
        "idx_tenant_sync_status_tenant_operation",
        "tenant_sync_status",
        ["tenant_id", "sync_operation"],
        unique=False,
        schema="query_store",
    )
    op.create_index(
        op.f("ix_query_store_tenant_sync_status_tenant_id"),
        "tenant_sync_status",
        ["tenant_id"],
        unique=False,
        schema="query_store",
    )

    op.add_column(
        "metric_sync_status",
        sa.Column(
            "sync_operation",
            sync_operation_enum,
            nullable=True,
        ),
        schema="query_store",
    )
    op.drop_index(
        op.f("idx_metric_sync_status_history"),
        table_name="metric_sync_status",
        schema="query_store",
        postgresql_using="gin",
    )
    op.drop_constraint(op.f("uq_metric_sync_status"), "metric_sync_status", schema="query_store", type_="unique")
    op.create_unique_constraint(
        "uq_metric_sync_status",
        "metric_sync_status",
        ["metric_id", "tenant_id", "grain", "sync_operation", "dimension_name", "sync_type"],
        schema="query_store",
    )
    op.create_index(
        "idx_metric_sync_status_operation", "metric_sync_status", ["sync_operation"], unique=False, schema="query_store"
    )
    op.execute("ALTER TABLE query_store.tenant_sync_status ENABLE ROW LEVEL SECURITY;")
    op.execute(
        "CREATE POLICY tenant_isolation_query_store_tenant_sync_status ON query_store.tenant_sync_status USING "
        "(tenant_id = (SELECT current_setting('app.current_tenant')::int));"
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index("idx_metric_sync_status_operation", table_name="metric_sync_status", schema="query_store")
    op.drop_constraint("uq_metric_sync_status", "metric_sync_status", schema="query_store", type_="unique")
    op.create_unique_constraint(
        op.f("uq_metric_sync_status"),
        "metric_sync_status",
        ["metric_id", "tenant_id", "grain", "dimension_name", "sync_type"],
        schema="query_store",
        postgresql_nulls_not_distinct=False,
    )
    op.create_index(
        op.f("idx_metric_sync_status_history"),
        "metric_sync_status",
        ["history"],
        unique=False,
        schema="query_store",
        postgresql_using="gin",
    )
    op.drop_column("metric_sync_status", "sync_operation", schema="query_store")

    op.drop_index(
        op.f("ix_query_store_tenant_sync_status_tenant_id"), table_name="tenant_sync_status", schema="query_store"
    )
    op.drop_index("idx_tenant_sync_status_tenant_operation", table_name="tenant_sync_status", schema="query_store")
    op.drop_index("idx_tenant_sync_status_status", table_name="tenant_sync_status", schema="query_store")
    op.drop_index(
        "idx_tenant_sync_status_last_sync",
        table_name="tenant_sync_status",
        schema="query_store",
        postgresql_ops={"last_sync_at": "DESC"},
    )
    op.drop_table("tenant_sync_status", schema="query_store")
    # Drop enums created in this migration
    op.execute("DROP TYPE IF EXISTS query_store.syncoperation;")
    # ### end Alembic commands ###
